{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = []\n",
    "\n",
    "class DataPoint:\n",
    "  def __init__(self, status, vars):\n",
    "    self.isTrue = status\n",
    "    self.title = vars[0]\n",
    "    self.text = vars[1]\n",
    "    self.subject = vars[2]\n",
    "    self.data = vars[3]\n",
    "\n",
    "  def print(self):\n",
    "    print(self.isTrue + \" - \" + self.title + \" - \" + self.text)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                                               text\n",
      "0      fake  Donald Trump just couldn t wish all Americans ...\n",
      "1      fake  House Intelligence Committee Chairman Devin Nu...\n",
      "2      fake  On Friday, it was revealed that former Milwauk...\n",
      "3      fake  On Christmas day, Donald Trump announced that ...\n",
      "4      fake  Pope Francis used his annual Christmas Day mes...\n",
      "5      fake  The number of cases of cops brutalizing and ki...\n",
      "6      fake  Donald Trump spent a good portion of his day a...\n",
      "7      fake  In the wake of yet another court decision that...\n",
      "8      fake  Many people have raised the alarm regarding th...\n",
      "9      fake  Just when you might have thought we d get a br...\n",
      "10     fake  A centerpiece of Donald Trump s campaign, and ...\n",
      "11     fake  Republicans are working overtime trying to sel...\n",
      "12     fake  Republicans have had seven years to come up wi...\n",
      "13     fake  The media has been talking all day about Trump...\n",
      "14     fake  Abigail Disney is an heiress with brass ovarie...\n",
      "15     fake  Donald Trump just signed the GOP tax scam into...\n",
      "16     fake  A new animatronic figure in the Hall of Presid...\n",
      "17     fake  Trump supporters and the so-called president s...\n",
      "18     fake  Right now, the whole world is looking at the s...\n",
      "19     fake  Senate Majority Whip John Cornyn (R-TX) though...\n",
      "20     fake  It almost seems like Donald Trump is trolling ...\n",
      "21     fake  In this #METOO moment, many powerful men are b...\n",
      "22     fake  As a Democrat won a Senate seat in deep-red Al...\n",
      "23     fake  Alabama is a notoriously deep red state. It s ...\n",
      "24     fake  A backlash ensued after Donald Trump launched ...\n",
      "25     fake  Donald Trump is afraid of strong, powerful wom...\n",
      "26     fake  Ronald Reagan is largely seen as the Messiah o...\n",
      "27     fake   Judge  Jeanine Pirro has continued her scream...\n",
      "28     fake  Donald Trump held a rally for Alabama Senate c...\n",
      "29     fake  When Sen. Al Franken (D-MN) announced his plan...\n",
      "...     ...                                                ...\n",
      "21387  true  TRIPOLI (Reuters) - Former Libyan Prime Minist...\n",
      "21388  true  LONDON (Reuters) - Britain on Wednesday outlin...\n",
      "21389  true  BERLIN (Reuters) - Chancellor Angela Merkel sa...\n",
      "21390  true  KARACHI, Pakistan (Reuters) - Pakistan has rej...\n",
      "21391  true  BUCHAREST (Reuters) - Romania s justice minist...\n",
      "21392  true  BEIRUT (Reuters) - Iran and Saudi Arabia will ...\n",
      "21393  true  COPENHAGEN (Reuters) - Police on Wednesday ide...\n",
      "21394  true  HONG KONG (Reuters) - Typhoon Hato, a maximum ...\n",
      "21395  true  WARSAW (Reuters) - Poland will allocate an add...\n",
      "21396  true  DUBAI (Reuters) - Fighters loyal to the armed ...\n",
      "21397  true  BERLIN (Reuters) - The leader of Germany s Soc...\n",
      "21398  true  SHANGHAI (Reuters) - An old review of an acade...\n",
      "21399  true  DUBAI (Reuters) - A 14-year-old boy who was de...\n",
      "21400  true  LONDON (Reuters) - Abdul Daoud spilt most of t...\n",
      "21401  true  BUENOS AIRES (Reuters) - Argentina s main labo...\n",
      "21402  true  ON BOARD A U.S. MILITARY AIRCRAFT (Reuters) - ...\n",
      "21403  true  WASHINGTON (Reuters) - The United States sugge...\n",
      "21404  true  WASHINGTON (Reuters) - The United States has d...\n",
      "21405  true  ISLAMABAD (Reuters) - Outlining a new strategy...\n",
      "21406  true  GENEVA (Reuters) - North Korea and the United ...\n",
      "21407  true  SAO PAULO (Reuters) - Cesar Mata Pires, the ow...\n",
      "21408  true  GENEVA (Reuters) - North Korea and the United ...\n",
      "21409  true  GENEVA (Reuters) - North Korea and the United ...\n",
      "21410  true  COPENHAGEN (Reuters) - Danish police said on T...\n",
      "21411  true  UNITED NATIONS (Reuters) - Two North Korean sh...\n",
      "21412  true  BRUSSELS (Reuters) - NATO allies on Tuesday we...\n",
      "21413  true  LONDON (Reuters) - LexisNexis, a provider of l...\n",
      "21414  true  MINSK (Reuters) - In the shadow of disused Sov...\n",
      "21415  true  MOSCOW (Reuters) - Vatican Secretary of State ...\n",
      "21416  true  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...\n",
      "\n",
      "[44869 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfFalse = pd.read_csv (r'Databases/Data1/Fake.csv')\n",
    "ds1 = pd.DataFrame()\n",
    "ds1[\"text\"] = dfFalse[\"text\"]\n",
    "ds1.insert(0, 'label', 'fake')\n",
    "dfTrue = pd.read_csv (r'Databases/Data1/True.csv')\n",
    "ds2 = pd.DataFrame()\n",
    "ds2[\"text\"] = dfTrue[\"text\"]\n",
    "ds2.insert(0, 'label', 'true')\n",
    "dataset1 = pd.concat([ds1, ds2])\n",
    "dataset1.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "print(dataset1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\" in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (4.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (40.8.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (1.16.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (2.21.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (8.1.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (2.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.1)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.3.9)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy) (0.0.0)\n",
      "^C\n",
      "Requirement already satisfied: en-core-web-sm==3.4.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl#egg=en_core_web_sm==3.4.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.4.0) (3.4.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\" in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.16.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.21.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (40.8.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.1.1)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2019.3.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.0.0)\n",
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m spacy download en_core_web_lg\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         text      lemma    POS                    explain  stopword\n",
      "0        When       when  SCONJ  subordinating conjunction      True\n",
      "1   Sebastian  Sebastian  PROPN                proper noun     False\n",
      "2       Thrun      Thrun  PROPN                proper noun     False\n",
      "3     started      start   VERB                       verb     False\n",
      "4     working       work   VERB                       verb     False\n",
      "5          on         on    ADP                 adposition      True\n",
      "6        self       self   NOUN                       noun     False\n",
      "7           -          -  PUNCT                punctuation     False\n",
      "8     driving      drive   VERB                       verb     False\n",
      "9        cars        car   NOUN                       noun     False\n",
      "10         at         at    ADP                 adposition      True\n",
      "11     Google     Google  PROPN                proper noun     False\n",
      "12         in         in    ADP                 adposition      True\n",
      "13       2007       2007    NUM                    numeral     False\n",
      "14          ,          ,  PUNCT                punctuation     False\n",
      "15        few        few    ADJ                  adjective      True\n",
      "16     people     people   NOUN                       noun     False\n",
      "17    outside    outside    ADV                     adverb     False\n",
      "18         of         of    ADP                 adposition      True\n",
      "19        the        the    DET                 determiner      True\n",
      "20    company    company   NOUN                       noun     False\n",
      "21       took       take   VERB                       verb     False\n",
      "22        him         he   PRON                    pronoun      True\n",
      "23  seriously  seriously    ADV                     adverb     False\n",
      "24          .          .  PUNCT                punctuation     False\n",
      "25          “          \"  PUNCT                punctuation     False\n",
      "26          I          I   PRON                    pronoun      True\n",
      "27        can        can    AUX                  auxiliary      True\n",
      "28       tell       tell   VERB                       verb     False\n",
      "29        you        you   PRON                    pronoun      True\n",
      "..        ...        ...    ...                        ...       ...\n",
      "36        car        car   NOUN                       noun     False\n",
      "37  companies    company   NOUN                       noun     False\n",
      "38      would      would    AUX                  auxiliary      True\n",
      "39      shake      shake   VERB                       verb     False\n",
      "40         my         my   PRON                    pronoun      True\n",
      "41       hand       hand   NOUN                       noun     False\n",
      "42        and        and  CCONJ   coordinating conjunction      True\n",
      "43       turn       turn   VERB                       verb     False\n",
      "44       away       away    ADV                     adverb     False\n",
      "45    because    because  SCONJ  subordinating conjunction      True\n",
      "46          I          I   PRON                    pronoun      True\n",
      "47        was         be    AUX                  auxiliary      True\n",
      "48        n’t        not   PART                   particle      True\n",
      "49      worth      worth    ADJ                  adjective     False\n",
      "50    talking       talk   VERB                       verb     False\n",
      "51         to         to    ADP                 adposition      True\n",
      "52          ,          ,  PUNCT                punctuation     False\n",
      "53          ”          \"  PUNCT                punctuation     False\n",
      "54       said        say   VERB                       verb     False\n",
      "55      Thrun      Thrun  PROPN                proper noun     False\n",
      "56          ,          ,  PUNCT                punctuation     False\n",
      "57         in         in    ADP                 adposition      True\n",
      "58         an         an    DET                 determiner      True\n",
      "59  interview  interview   NOUN                       noun     False\n",
      "60       with       with    ADP                 adposition      True\n",
      "61     Recode     Recode  PROPN                proper noun     False\n",
      "62    earlier      early    ADV                     adverb     False\n",
      "63       this       this    DET                 determiner      True\n",
      "64       week       week   NOUN                       noun     False\n",
      "65          .          .  PUNCT                punctuation     False\n",
      "\n",
      "[66 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "LGVars = pd.DataFrame()\n",
    "import numpy as np\n",
    "import spacy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = sp.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process whole documents\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)\n",
    "\n",
    "cols = (\"text\", \"lemma\", \"POS\", \"explain\", \"stopword\")\n",
    "rows = []\n",
    "for t in doc:\n",
    "    row = [t.text, t.lemma_, t.pos_, sp.explain(t.pos_), t.is_stop]\n",
    "    rows.append(row)\n",
    "df = pd.DataFrame(rows, columns=cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from xgboost) (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\jjfri\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from xgboost) (1.16.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                               text\n",
      "0  fake  Donald Trump just couldn t wish all Americans ...\n",
      "1  fake  House Intelligence Committee Chairman Devin Nu...\n",
      "2  fake  On Friday, it was revealed that former Milwauk...\n",
      "3  fake  On Christmas day, Donald Trump announced that ...\n",
      "4  fake  Pope Francis used his annual Christmas Day mes...\n",
      "Number of fake messages: 23452\n",
      "Number of true messages: 21417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jjfri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfFalse = pd.read_csv (r'Databases/Data1/Fake.csv')\n",
    "ds1 = pd.DataFrame()\n",
    "ds1[\"text\"] = dfFalse[\"text\"]\n",
    "ds1.insert(0, 'label', 'fake')\n",
    "dfTrue = pd.read_csv (r'Databases/Data1/True.csv')\n",
    "ds2 = pd.DataFrame()\n",
    "ds2[\"text\"] = dfTrue[\"text\"]\n",
    "ds2.insert(0, 'label', 'true')\n",
    "dataset1 = pd.concat([ds1, ds2])\n",
    "dataset1.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "\n",
    "# Import libraries\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(dataset1.head(5))\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def text_preprocess(message):\n",
    "    # Remove punctuations\n",
    "    nopunc = [char for char in message if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again\n",
    "    nopunc = \"\".join(nopunc)\n",
    "    nopunc = nopunc.lower()\n",
    "\n",
    "    # Remove any stopwords and non-alphabetic characters\n",
    "    nostop = [\n",
    "        word\n",
    "        for word in nopunc.split()\n",
    "        if word.lower() not in stopwords.words(\"english\") and word.isalpha()\n",
    "    ]\n",
    "\n",
    "    return nostop\n",
    "\n",
    "\n",
    "false_text = dataset1[dataset1[\"label\"] == \"fake\"][\"text\"]\n",
    "true_text = dataset1[dataset1[\"label\"] == \"true\"][\"text\"]\n",
    "print(f\"Number of fake messages: {len(false_text)}\")\n",
    "print(f\"Number of true messages: {len(true_text)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################### TAKES FOREVER TO PROSESS\n",
    "from sklearn.utils import shuffle\n",
    "data_shuffled = dataset1.sample(len(dataset1))\n",
    "#dataset1 = shuffle(dataset1)\n",
    "#dataset1 = dataset1.iloc[0:500] # 0.0878 seconds per row // 89.922 min for entire dataset\n",
    "\n",
    "# Remove punctuations/stopwords from all messages\n",
    "data_shuffled[\"text\"] = data_shuffled[\"text\"].apply(text_preprocess)\n",
    "data_shuffled.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_shuffled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-480040600255>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert messages (as lists of string tokens) to strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_shuffled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shuffled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata_shuffled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Initialize count vectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_shuffled' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert messages (as lists of string tokens) to strings\n",
    "data_shuffled[\"text\"] = data_shuffled[\"text\"].agg(lambda x: \" \".join(map(str, x)))\n",
    "data_shuffled.head()\n",
    "\n",
    "# Initialize count vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "bow_transformer = vectorizer.fit(data_shuffled[\"text\"])\n",
    "\n",
    "# Fetch the vocabulary set\n",
    "print(f\"20 BOW Features: {vectorizer.get_feature_names()[20:40]}\")\n",
    "print(f\"Total number of vocab words: {len(vectorizer.vocabulary_)}\")\n",
    "\n",
    "# Convert strings to vectors using BoW\n",
    "dataset1_bow = bow_transformer.transform(data_shuffled[\"text\"])\n",
    "\n",
    "# Print the shape of the sparse matrix and count the number of non-zero occurrences\n",
    "print(f\"Shape of sparse matrix: {dataset1_bow.shape}\")\n",
    "print(f\"Amount of non-zero occurrences: {dataset1_bow.nnz}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44869, 198902)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20454</th>\n",
       "      <td>0</td>\n",
       "      <td>sheriff clarke weighs violence trump rally san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12290</th>\n",
       "      <td>1</td>\n",
       "      <td>london reuters one chennai six group exbritish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15430</th>\n",
       "      <td>1</td>\n",
       "      <td>brussels reuters eu diplomats start sketching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19635</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>1</td>\n",
       "      <td>washington reuters donald nominee head cia sou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "20454      0  sheriff clarke weighs violence trump rally san...\n",
       "12290      1  london reuters one chennai six group exbritish...\n",
       "15430      1  brussels reuters eu diplomats start sketching ...\n",
       "19635      0                                                   \n",
       "6370       1  washington reuters donald nominee head cia sou..."
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(dataset1_bow)\n",
    "\n",
    "# Transform entire BoW into tf-idf corpus\n",
    "messages_tfidf = tfidf_transformer.transform(dataset1_bow)\n",
    "print(messages_tfidf.shape)\n",
    "\n",
    "# Convert spam and ham labels to 0 and 1 (or, vice-versa)\n",
    "FactorResult = pd.factorize(data_shuffled[\"label\"])\n",
    "data_shuffled[\"label\"] = FactorResult[0]\n",
    "data_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset features size: (35895, 198902)\n",
      "train dataset label size: (35895,)\n",
      "test dataset features size: (8974, 198902)\n",
      "test dataset label size: (8974,)\n",
      "Accuracy of Train dataset: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset to train and test sets\n",
    "msg_train, msg_test, label_train, label_test = train_test_split(\n",
    "    messages_tfidf, data_shuffled[\"label\"], test_size=0.2\n",
    ")\n",
    "\n",
    "print(f\"train dataset features size: {msg_train.shape}\")\n",
    "print(f\"train dataset label size: {label_train.shape}\")\n",
    "\n",
    "print(f\"test dataset features size: {msg_test.shape}\")\n",
    "print(f\"test dataset label size: {label_test.shape}\")\n",
    "\n",
    "# Train an xgboost classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Instantiate our model\n",
    "clf = XGBClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf.fit(msg_train, label_train)\n",
    "clf.save_model(\"CLF_model.json\")\n",
    "\n",
    "# Make predictions\n",
    "predict_train = clf.predict(msg_train)\n",
    "\n",
    "print(\n",
    "    f\"Accuracy of Train dataset: {metrics.accuracy_score(label_train, predict_train):0.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44869, 198902)\n",
      "(44869, 198902)\n"
     ]
    }
   ],
   "source": [
    "print(messages_tfidf.shape)\n",
    "print(dataset1_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label                                               text\n",
      "0  unknown  first presidential visit saudi arabia mr biden...\n",
      "20 BOW Features: ['bearing', 'biden', 'bin', 'bint', 'blossoming', 'body', 'bolster', 'break', 'broadcast', 'bump', 'candidate', 'capacity', 'carpet', 'cases', 'channel', 'chilly', 'chinese', 'climbed', 'close', 'closely']\n",
      "Total number of vocab words: 214\n",
      "Shape of sparse matrix: (1, 214)\n",
      "Amount of non-zero occurrences: 214\n",
      "  (0, 2722)\t0.06959839237859877\n",
      "  (0, 3609)\t0.17982199714902203\n",
      "  (0, 4130)\t0.08077802753143525\n",
      "  (0, 10848)\t0.04988820325808513\n",
      "  (0, 11668)\t0.14767776648691322\n",
      "  (0, 15068)\t0.05321019110868219\n",
      "  (0, 16735)\t0.06015266876749907\n",
      "  (0, 20286)\t0.08782879712381554\n",
      "  (0, 22551)\t0.09585195343529387\n",
      "  (0, 22577)\t0.0645642653929726\n",
      "  (0, 25183)\t0.053861511505976956\n",
      "  (0, 25282)\t0.1279474895158867\n",
      "  (0, 26394)\t0.12434873495168294\n",
      "  (0, 26670)\t0.07663824923599856\n",
      "  (0, 26976)\t0.054587562030027854\n",
      "  (0, 29099)\t0.11320232571633453\n",
      "  (0, 31979)\t0.19214966900662214\n",
      "  (0, 32332)\t0.059382045511562453\n",
      "  (0, 34427)\t0.07923307745479057\n",
      "  (0, 35129)\t0.0711913527038058\n",
      "  (0, 35741)\t0.05217033590715835\n",
      "  (0, 37088)\t0.11803985003720686\n",
      "  (0, 39656)\t0.06750352181636683\n",
      "  (0, 42123)\t0.06993105057181855\n",
      "  (0, 42703)\t0.05534976528729201\n",
      "  :\t:\n",
      "  (35894, 191875)\t0.04461845508585345\n",
      "  (35894, 192338)\t0.2169284463160748\n",
      "  (35894, 192362)\t0.10824816551414602\n",
      "  (35894, 192385)\t0.03469935462915401\n",
      "  (35894, 192854)\t0.024002437783274336\n",
      "  (35894, 193105)\t0.011927766603219042\n",
      "  (35894, 193215)\t0.015619015256361127\n",
      "  (35894, 193511)\t0.01734375456598839\n",
      "  (35894, 193538)\t0.014343590865669541\n",
      "  (35894, 193727)\t0.03467672746020623\n",
      "  (35894, 193922)\t0.014466569975501631\n",
      "  (35894, 194069)\t0.016590524050118703\n",
      "  (35894, 194468)\t0.012203655237457377\n",
      "  (35894, 195059)\t0.015218039466894349\n",
      "  (35894, 195118)\t0.13012649472564408\n",
      "  (35894, 195278)\t0.03738761763179998\n",
      "  (35894, 195447)\t0.014741915093351812\n",
      "  (35894, 195473)\t0.032949127797637257\n",
      "  (35894, 195717)\t0.01845034517202538\n",
      "  (35894, 195911)\t0.011693418684487986\n",
      "  (35894, 196852)\t0.040154977914311385\n",
      "  (35894, 197131)\t0.03396303577285389\n",
      "  (35894, 197187)\t0.0143071550898414\n",
      "  (35894, 197484)\t0.01021546046768791\n",
      "  (35894, 198018)\t0.023964096070352346\n"
     ]
    }
   ],
   "source": [
    "NYTwebsite_text = \"\"\"On his first presidential visit to Saudi Arabia, Mr. Biden received an unsmiling fist bump from the crown prince before meeting King Salman. Their body language is being parsed amid tensions over the Saudi human rights record. President Biden used his visit to Israel this week to bolster the blossoming relationship between Israel and a handful of Arab states. But it is Mr. Biden’s own relationship with Saudi Arabia that looms largest over the second part of his four-day trip, and the kingdom’s welcome of him was being closely watched as an indication of how the overall visit might unfold.\n",
    "\n",
    "As Air Force One landed, just before 6 p.m. local time, the Saudi reception, while led by a senior member of the royal family, was decidedly lacking in pomp. Lining the lilac carpet were a small number of uniformed security officers bearing swords, but even fewer than were dispatched to welcome President Barack Obama when he arrived in the kingdom to a chilly reception in 2016.\n",
    "\n",
    "Mr. Biden emerged from the plane and made his way down the stairs for his first visit to Saudi Arabia as president, wearing his aviator shades, waving and looking serious. He was greeted by Princess Reema bint Bandar Al Saud, the Saudi ambassador to Washington, and Prince Khalid Al Faisal, a senior member of the royal family who is the governor of Mecca and is close to King Salman.\n",
    "\n",
    "The president climbed into his limousine just two minutes after disembarking. He was  taken directly to meet the king.\n",
    "\n",
    "Arriving at the al-Salam palace, Mr. Biden was met by Crown Prince Mohammed bin Salman, and the two exchanged an apparently wordless fist bump before the prince led the president inside.\n",
    "\n",
    "The Saudi-owned Al Arabiya satellite channel broadcast images of Mr. Biden being warmly welcomed by King Salman, and shaking his hand. Other images showed Mr. Biden and the king sitting next to each other in armchairs in an ornate room during a meeting, with other U.S. and Saudi officials, including Prince Mohammed, sitting nearby.\n",
    "\n",
    "Later, Mr. Biden is to hold a “working session” along with his team with Prince Mohammed and various Saudi ministers.Biden’s arrival in Saudi Arabia was polite but perfunctory compared with the enthusiastic greeting President Donald J. Trump received in 2017 when King Salman welcomed him on the tarmac. Mr. Trump made Saudi Arabia his first overseas destination as president, a sharp break with tradition and a sign of how closely he would align his administration with the Saudis.\n",
    "\n",
    "Even though Mr. Biden vowed as a candidate to punish Saudi Arabia over Mr. Khashoggi’s murder by making the kingdom a “pariah,” the president decided that it was worth the political cost of traveling there this week to counter Chinese influence, press for additional oil production and encourage closer ties with Israel.\n",
    "\n",
    "In other cases, recently including Cuba and Venezuela, Mr. Biden has stressed that his administration is making democracy and respect for human rights the paramount consideration for dealing with other nations’ leaders. But on Thursday in Jerusalem, he said he was going to Saudi Arabia in order to promote U.S. interests.\n",
    "\n",
    "Those include getting the kingdom to pump more oil from its somewhat modest spare capacity.\"\"\"\n",
    "dict = {'label':['unknown'],\n",
    "        'text':[NYTwebsite_text],\n",
    "       }\n",
    "WP = pd.DataFrame(dict)\n",
    "WP[\"text\"] = WP[\"text\"].apply(text_preprocess)\n",
    "\n",
    "# Convert messages (as lists of string tokens) to strings\n",
    "WP[\"text\"] = WP[\"text\"].agg(lambda x: \" \".join(map(str, x)))\n",
    "print(WP.head())\n",
    "\n",
    "# Initialize count vectorizer\n",
    "vectiz = CountVectorizer()\n",
    "bow_trans = vectiz.fit(WP[\"text\"])\n",
    "\n",
    "# Fetch the vocabulary set\n",
    "print(f\"20 BOW Features: {vectiz.get_feature_names()[20:40]}\")\n",
    "print(f\"Total number of vocab words: {len(vectiz.vocabulary_)}\")\n",
    "\n",
    "# Convert strings to vectors using BoW\n",
    "WP_bow = bow_trans.transform(WP[\"text\"])\n",
    "\n",
    "# Print the shape of the sparse matrix and count the number of non-zero occurrences\n",
    "print(f\"Shape of sparse matrix: {WP_bow.shape}\")\n",
    "print(f\"Amount of non-zero occurrences: {WP_bow.nnz}\")\n",
    "\n",
    "tfidf_trans = TfidfTransformer().fit(WP_bow)\n",
    "\n",
    "# Transform entire BoW into tf-idf corpus\n",
    "WP_tfidf = tfidf_trans.transform(WP_bow)\n",
    "#print(clf.predict(WP_tfidf))\n",
    "\n",
    "#prediction = clf.predict(WP_tfidf)\n",
    "#print(prediction)\n",
    "print(msg_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20454    sheriff clarke weighs violence trump rally san...\n",
      "12290    london reuters one chennai six group exbritish...\n",
      "15430    brussels reuters eu diplomats start sketching ...\n",
      "19635                                                     \n",
      "6370     washington reuters donald nominee head cia sou...\n",
      "1461     washington reuters us health human services se...\n",
      "821      washingtonkhobar saudi arabia reuters us presi...\n",
      "10819    white house confirmed fox business priebus wou...\n",
      "16254    kinshasa reuters democratic republic congo mus...\n",
      "528      washington reuters republican senator rand pau...\n",
      "Name: text, dtype: object\n",
      "Accuracy of the model: 0.998\n",
      "(1, 198902)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-0a45811751d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# an example prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_transformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbow_transformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_shuffled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m print(\n",
      "\u001b[1;32mc:\\Users\\jjfri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1086\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jjfri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 943\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    944\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jjfri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    327\u001b[0m                                                tokenize)\n\u001b[0;32m    328\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 329\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jjfri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jjfri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "print(data_shuffled[\"text\"].head(10))\n",
    "\n",
    "# print the overall accuracy of the model\n",
    "label_predictions = clf.predict(msg_test)\n",
    "print(f\"Accuracy of the model: {metrics.accuracy_score(label_test, label_predictions):0.3f}\")\n",
    "\n",
    "# an example prediction\n",
    "print(msg_test.shape)\n",
    "print(clf.predict(tfidf_transformer.transform(bow_transformer.transform([data_shuffled[\"text\"][9]]))))\n",
    "\n",
    "print(\n",
    "    \"predicted:\",\n",
    "    clf.predict(\n",
    "        tfidf_transformer.transform(bow_transformer.transform([data_shuffled[\"text\"][9]]))\n",
    "    )[0],\n",
    ")\n",
    "\n",
    "print(\"expected:\", data_shuffled[\"label\"][9])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7f9b176e99b0b7699e163eb9975710d46148f2747eaa4ceb3869c0d6f92460c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
